<!-- CUDA Tutorial 02/05 -->

Docs :
* https://tcuvelier.developpez.com/tutoriels/gpgpu/cuda/introduction/
* https://devblogs.nvidia.com/even-easier-introduction-cuda/
* http://www.nvidia.com/docs/IO/116711/sc11-cuda-c-basics.pdf

* [Introduction CUDA](#introduction-cuda)
* [Vocabulary](#vocabulary)
* [Using a GPU](#using-a-gpu)
* [Memories](#memories)
* [Shaders](#shaders)
* [Coding](#coding)

## Introduction CUDA

* C, C++, Fortran utilisables -> derived from C
* existing libraries CuBLAS, CuFFT for linear algebra/FFT use

## Vocabulary

* host = CPU asking to the GPU to execute computations
* kernel = parallel portion of code to execute -> each instance is a thread
* grid = set of blocks = each block is a set of threads
* each block executes independantly from the others (**parallel computation**) -> threads can only communicate with other threads from the same block
* warp = set of 32 threads simultaneously executed
* block = like a multiprocessor with threads (like a processor)

## Using a GPU

### Some info

* a GPU = at least 32 processors
* vectors have to be used for real gains

### Computation accuracy

* no exception, no NaN exception
* operands not normalized going to 0
* addition/substraction = 1 instruction

## Memories

* Global memory (DRAM) = can be used anywhere from CUDA (long access time to perform gathering/scattering operations)
* Local memory : only used for specific variable = for example to store stg that is too large for global memory	
* Constant memory : hidden 8kB memory = reading operation really fast (1 cycle as long as threads from the same warp read at the same address)
* texture memory : optimized for 2D-space, with reading cost really low -> enable to perform bilinear/trilinear filters in a simple way (image processing optimized)
* shared memory : between ALU and DRAM -> faster than local memory, divided in memory modules (bank). As long as threads from the same warp access to different memory modules, there is no conflict and operations can be performed simultaneously. For the moment, 32 warp <-> 16 banks (each one with 32 bits-bandwidth and 1ko memory) 
* 8192 registers by multiprocessor
* system memory can be used but introduces more latency that local memory (700-800 cycles).

## Shaders

* Shaders are the fastest processors in GPU
* each shader : set of texture processor cluster (TPC)
* each TPC = 1 TEX (1 computing unit for texture) and 2 flows treatment unit (Streaming multiprocessor).

## Coding

### Prerequisites

* A function that the GPU can run is called a kernel in CUDA. To declare that, a specifier __global__ should be added.
* Code for CPU called host code and code for GPU called device code.

### Memory Allocation

** Allocate : 

Basic code to allocate :
```
float *x;
cudaMallocManaged(&x, N*sizeof(float));
```

Basic code to free :
```
cudaFree(x);
```

### Calling a CUDA kernel :

Example of a C host code :
```
__global__
void add(int n, float *x, float *y)
{
  for (int i = 0; i < n; i++)
      y[i] = x[i] + y[i];
}
```

Call for GPU kernel :
```
add<<<1, 1>>>(N, x, y);
```

Wait for GPU to finish before accessing on host :
```
cudaDeviceSynchronize();
```

### Making execution parallel

**add<<<1, 1>>>** do not use parallelism.

We can modify the 2 parameters to take advantage of parallelism.
First parameter : Number of thread blocks
Second parameter : Number of threads used in a thread block (multiple of 32 size)

Modifying CUDA kernel to use parallelism :

We call **add<<<1, 256>>>** to use 256 threads
```
int index = threadIdx.x; // id of the current the thread within the block
int stride = blockDim.x; // number of threads used in the block
```

Performing add function is now :
```
for (int i = index; i < n; i += stride)
      y[i] = x[i] + y[i];
```

If we imagine that N is enough large, we have to use multiple blocks. In this case, we will use :
```
int blockSize = 256;
int numBlocks = (N + blockSize - 1) / blockSize;
add<<<numBlocks, blockSize>>>(N, x, y);
```

Consequently, we have to modify the code :
```
int index = blockIdx.x * blockDim.x + threadIdx.x;
int stride = blockDim.x * gridDim.x;
for (int i = index; i < n; i += stride)
	y[i] = x[i] + y[i];
```	
	
### Profiling

```
nvprof ./add_cuda
```